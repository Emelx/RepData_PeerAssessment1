# with the following instruction a vector is returned whose elements are the count of na per each column of data
napercolumn<-apply(data,2,function(x) sum(is.na(x)))
natot<-sum(napercolumn)
if (natot>0) {
stop("Data contains na. Program aborted")
}
library("neuralnet")
if (natot>=0) {
set.seed(500)
library(MASS)
data <- Boston
# applies the function sum(is.na(x)) defined directly inside apply() (note that no curly brackets are needed).
# since the parameter 2 is passed to apply(), the function is applied to each column of data.
# with the following instruction a vector is returned whose elements are the count of na per each column of data
napercolumn<-apply(data,2,function(x) sum(is.na(x)))
natot<-sum(napercolumn)
if (natot>=0) {
stop("Data contains na. Program aborted")
}
library("neuralnet")
index <- sample(1:nrow(data),round(0.75*nrow(data)))
index
index <- sample(1:nrow(data),round(0.75*nrow(data)))
class(index)
index
round(0.75*nrow(data))
NRO
nrow(data)
506*0.75
head(data)
train <- data[index,]
test <- data[-index,]
lm.fit <- glm(medv~., data=train)
lm.fit
summary(lm.fit)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
install.packages("swirl")
packageVersion("swirl")
library(swirl)
install_from_swirl("Regression Models")
swirl()
plot(child~parent,galton)
plot(jitter(child,4)~parent,galton)
reglint<-lm(child~parent,galton)
regrlint<-lm(child~parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3,col='red')
summary(regrline)
fit <- lm(child ~ parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
osl.ic<-fit.coef[1]
osl.ic<-fit$coef[1]
ols.ic<-fit$coef[1]
ols.slope<-fit$coef[2]
rhs-lhs
lhs-rhs
all.equal(lhs,rhs)
varChild<-var(galton$child)
varRes<-var(fit$residuals)
varEst<-var(est(ol.slope))
varEst<-var(est(ols.slope,ols.ic))
all.eqal(varChild,varre)
all.eqal(varChild,varRes+varEst)
all.equal(varChild,varRes+varEst)
efit<-lm(accel~mag+dist,attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
cor(gpa_nor, gch_nor)
l_nor<-lm(gch_nor~gpa_nor)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
f<-lm(y ~ x - 1)
summary(f)
data("mtcars")
f<-lm(mtcars$mpg~mtcars$wt)
summary(f)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
scale(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
f<-lm(y ~ x)
summary(f)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
f<-lm(x ~ x)
y <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
f<-lm(y ~ x)
summary(f)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
lm(x~x)
lm(x)
library(manipulate)
library(UsingR); data(galton)
install.packages("UsingR")
library(UsingR); data(galton)
gallton
galton
library(manipulate)
par(mfrow=c(1,2))
hist(galton$child,col="blue",breaks=100)
hist(galton$parent,col="blue",breaks=100)
hist(galton$parent,col="blue",breaks=10)
hist(galton$parent,col="blue",breaks=100)
hist(galton$parent,col="blue",breaks=100)
hist(galton$child,col="blue",breaks=100)
install.package("manipulate")
install.packages("manipulate")
library(manipulate)
myHist <- function(mu){
hist(galton$child,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
hist(galton$child,col="blue",breaks=100)
meanChild <- mean(galton$child)
lines(rep(meanChild,100),seq(0,150,length=100),col="red",lwd=5
)
mse <- mean((galton$child - mu)^2)
mu=seq(65:70:0.1)
mu
?seq
mu<-seq(65,70,by=0.1)
mu
mse <- mean((galton$child - mu)^2)
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = slider(0.6, 1.2, step = 0.02))
manipulate(myPlot(beta), beta = slider(0.6, 1.2, step = 0.02))
lm(I(child - mean(child))~ I(parent - mean(parent)) - 1, data = galton)
plot(galton$parent,galton$child,pch=19,col="blue")
?abline
a<-lm(I(child - mean(child))~ I(parent - mean(parent)) - 1, data = galton)
abline(a$coefficients[1]
)
a$coefficients[1]
a$coefficients[2]
a$coefficients[0]
abline(0,a$coefficients[1])
abline(0,a$coefficients[1],cex=2,pch=19)
plot(galton$parent,galton$child,pch=19,col="blue")
abline(0,a$coefficients[1],cex=2,pch=19)
ibrary(UsingR)
data(diamond)
library(ggplot2)
g = ggplot(diamond, aes(x = carat, y = price))
g = g + xlab("Mass (carats)")
g = g + ylab("Price (SIN $)")
g = g + geom_point(size = 7, colour = "black", alpha=0.5)
g = g + geom_point(size = 5, colour = "blue", alpha=0.2)
g = g + geom_smooth(method = "lm", colour = "black")
g
fit <- lm(price ~ carat, data = diamond)
coef(fit)
fit2 <- lm(price ~ I(carat - mean(carat)), data = diamond)
coef(fit2)
round(coef(fit2)[1], 1)
Thus $`r round(coef(fit2)[1], 1)` is the expected price for
the average sized diamond of the data (`r mean(diamond$carat)` carats).
`r mean(diamond$carat)`
mean(diamond$carat)
data(diamond)
y <- diamond$price; x <- diamond$carat; n <- length(y)
fit <- lm(y ~ x)
e <- resid(fit)
yhat <- predict(fit)
max(abs(e -(y - yhat)))
max(abs(e - (y - coef(fit)[1] - coef(fit)[2] * x)))
library(UsingR)
data(diamond)
library(ggplot2)
g = ggplot(diamond, aes(x = carat, y = price))
g = g + xlab("Mass (carats)")
g = g + ylab("Price (SIN $)")
g = g + geom_smooth(method = "lm", colour = "black")
g = g + geom_point(size = 7, colour = "black", alpha=0.5)
g = g + geom_point(size = 5, colour = "blue", alpha=0.2)
g
```
data(diamond)
y <- diamond$price; x <- diamond$carat; n <- length(y)
fit <- lm(y ~ x)
e <- resid(fit)
yhat <- predict(fit)
max(abs(e -(y - yhat)))
max(abs(e - (y - coef(fit)[1] - coef(fit)[2] * x)))
plot(diamond$carat, diamond$price,
xlab = "Mass (carats)",
ylab = "Price (SIN $)",
bg = "lightblue",
col = "black", cex = 2, pch = 21,frame = FALSE)
abline(fit, lwd = 2)
for (i in 1 : n)
lines(c(x[i], x[i]), c(y[i], yhat[i]), col = "red" , lwd = 2)
plot(x, e,
xlab = "Mass (carats)",
ylab = "Residuals (SIN $)",
bg = "lightblue",
col = "black", cex = 2, pch = 21,frame = FALSE)
abline(h = 0, lwd = 2)
for (i in 1 : n)
lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
x = runif(100, -3, 3); y = x + sin(x) + rnorm(100, sd = .2);
library(ggplot2)
g = ggplot(data.frame(x = x, y = y), aes(x = x, y = y))
g = g + geom_smooth(method = "lm", colour = "black")
g = g + geom_point(size = 7, colour = "black", alpha = 0.4)
g = g + geom_point(size = 5, colour = "red", alpha = 0.4)
g
g = ggplot(data.frame(x = x, y = resid(lm(y ~ x))),
aes(x = x, y = y))
g = g + geom_hline(yintercept = 0, size = 2);
g = g + geom_point(size = 7, colour = "black", alpha = 0.4)
g = g + geom_point(size = 5, colour = "red", alpha = 0.4)
g = g + xlab("X") + ylab("Residual")
g
x <- runif(100, 0, 6); y <- x + rnorm(100,  mean = 0, sd = .001 * x);
g = ggplot(data.frame(x = x, y = y), aes(x = x, y = y))
g = g + geom_smooth(method = "lm", colour = "black")
g = g + geom_point(size = 7, colour = "black", alpha = 0.4)
g = g + geom_point(size = 5, colour = "red", alpha = 0.4)
g
g = ggplot(data.frame(x = x, y = resid(lm(y ~ x))),
aes(x = x, y = y))
g = g + geom_hline(yintercept = 0, size = 2);
g = g + geom_point(size = 7, colour = "black", alpha = 0.4)
g = g + geom_point(size = 5, colour = "red", alpha = 0.4)
g = g + xlab("X") + ylab("Residual")
g
diamond$e <- resid(lm(price ~ carat, data = diamond))
g = ggplot(diamond, aes(x = carat, y = e))
g = g + xlab("Mass (carats)")
g = g + ylab("Residual price (SIN $)")
g = g + geom_hline(yintercept = 0, size = 2)
g = g + geom_point(size = 7, colour = "black", alpha=0.5)
g = g + geom_point(size = 5, colour = "blue", alpha=0.2)
g
e = c(resid(lm(price ~ 1, data = diamond)),
resid(lm(price ~ carat, data = diamond)))
fit = factor(c(rep("Itc", nrow(diamond)),
rep("Itc, slope", nrow(diamond))))
g = ggplot(data.frame(e = e, fit = fit), aes(y = e, x = fit, fill = fit))
g = g + geom_dotplot(binaxis = "y", size = 2, stackdir = "center", binwidth = 20)
g = g + xlab("Fitting approach")
g = g + ylab("Residual price")
g
y <- diamond$price; x <- diamond$carat; n <- length(y)
fit <- lm(y ~ x)
summary(fit)$sigma
sqrt(sum(resid(fit)^2) / (n - 2))
require(stats); require(graphics); data(anscombe)
ff <- y ~ x
mods <- setNames(as.list(1:4), paste0("lm", 1:4))
for(i in 1:4) {
ff[2:3] <- lapply(paste0(c("y","x"), i), as.name)
## or   ff[[2]] <- as.name(paste0("y", i))
##      ff[[3]] <- as.name(paste0("x", i))
mods[[i]] <- lmi <- lm(ff, data = anscombe)
#print(anova(lmi))
}
op <- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))
for(i in 1:4) {
ff[2:3] <- lapply(paste0(c("y","x"), i), as.name)
plot(ff, data = anscombe, col = "red", pch = 21, bg = "orange", cex = 1.2,
xlim = c(3, 19), ylim = c(3, 13))
abline(mods[[i]], col = "blue")
}
mtext("Anscombe's 4 Regression data sets", outer = TRUE, cex = 1.5)
par(op)
install.packages('base64enc')
swirl()
swirl()
library(swirl)
rm(list=ls())
library(swirl)
swirl()
fit<-lm(child~parent, galton)
sqrt(sum(resid(fit)^2) / (n - 2))
sqrt(sum(resid(fit$residuals)^2) / (n - 2))
sqrt(sum((fit$residuals)^2) / (n - 2))
sqrt(sum(fit$residuals^2) / (n - 2))
sum(resid(fit))
sum(fit$residuals)
summary(fit)$sigma
deviance(fit)7(n-2)
deviance(fit)/(n-2)
sqrt(deviance(fit)/(n-2))
mu<-mean(galton$child)
sTot<-sqrt(sum((galton$child-mu)^2))
sTot<-sum((galton$child-mu)^2)
sRes<-sum(deviance(fit)^2)
sRes<-deviance(fit)
1-sRes/sTot
summary(fit)$r
summary(fit)$r.squared
summary(fit)$r.squareds
summary(fit)$r.squared
cor(galton$child,galton$parent)
cor(galton$child,galton$parent)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit<-lm(Volume~Girth+Height+Constant-1,trees)
trees2<-eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
lm(Fertility~, swiss)
lm(Fertility~., swiss)
all<-lm(Fertility~., swiss)
summary(all)
lm(Fertility~Agricolture, swiss)
lm(Fertility~agricolture, swiss)
lm(Fertility~Agriculture, swiss)
summary(lm(Fertility ~ Agriculture, swiss))
cor(swiss$Education,swiss$Examination)
cor(swiss$Education,swiss$Agruculture)
cor(swiss$Education,swiss$Agriculture)
makelms()
ec<-swiss$Examination+swiss$Catholic
efit<-lm(Fertility~. + ec, swiss)
coef(all)-coef(efit)
all$coefficients-efit$coefficients
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit<-lm(x~y)
fit
summary(fit)
fit<-lm(y~x)
summary(fit)
x
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
x
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit<-lm(y~x)
summry(fit)
summary(fit)
fit$residuals
sqrt(sum(fit$residuals^2)/9)
sqrt(sum(fit$residuals^2)/7)
data("mtcars")
fit<-lm(mpg~weight, mtcars)
names(mtcars)
fit<-lm(mpg~wt, mtcars)
summary(fit)
mpgHat<-predict(fit, mean(mtcars$wt))
new<-data.frame(wt=mean(mtcars$wt))
mpgHat<-predict(fit,new)
mpgHat
20.
20.09062-3*3.046
20.09062-18.991
ans
1.09962/3
?mtcars
new
new<-data.frame(wt=3
)
new
mpgHat<-predict(fit,new)
mpgHat
summary(mpgHat)
summary(fit)
-5.3445*2
10.689-3*0.5591
fit<-lm(mpg~wt, mtcars)
fit1<-lm(mpg~wt-1, mtcars)
sum(fit$residuals^2)
sum(fit$residuals^2)/sum(fit1$residuals^2)
# Clean upworkspace
rm(list=ls())
# 1. Code for reading in the dataset and/or processing the data
setwd("C:/Users/Massimo/Documents/Coursera/Data Science Specialization/5 - Reproducible Research/CourseProject1")
if (!file.exists("activity.csv")) {
unzip("activity.zip")
}
rawdata <- read.csv("activity.csv", colClass=c('integer', 'Date', 'integer'))
# 2. Histogram of the total number of steps taken each day
steps <- aggregate(steps ~ date, data=rawdata, FUN=sum, na.rm=TRUE)
names(steps)<-c("date","count")
library(ggplot2)
barplot(steps$count, names.arg=steps$date, main="Total number of steps taken each day",
xlab="date", ylab="steps count")
# 3. Mean and median number of steps taken each day
mean.step.eachday <-  mean(steps$count, na.rm=TRUE)
median.stem.eachday <- median(steps$count, na.rm=TRUE)
# 4. Time series plot of the average number of steps taken
avgs <- aggregate(x=list(steps=rawdata$steps), by=list(interval=rawdata$interval),
FUN=mean, na.rm=TRUE)
plot(avgs, type='l', main="Average number of steps taken")
# 5. The 5-minute interval that, on average, contains the maximum number of steps
avgs.maxnumsteps <- avgs[which.max(avgs$steps),]
# 6. Code to describe and show a strategy for imputing missing data
# Replace each missing value in an interval with the mean value of the day the interval belong to
data <- merge(rawdata, steps, by="date")
data["noNAsteps"] <- data$steps
nas <- is.na(data$steps)
data$noNAsteps[nas] <- data$count[nas]
# 7. Histogram of the total number of steps taken each day after missing values are imputed
steps <- aggregate(count ~ date, data=data, FUN=sum)
barplot(steps$count, names.arg=steps$date, main="Total number of steps taken each day\nafter missing values are imputed",
xlab="date", ylab="steps count")
# 8. Panel plot comparing the average number of steps taken per 5-minute interval across weekdays and weekends
GetwdORwe <- function(date)
{
if (weekdays(date) %in% c("Saturday", "Sunday"))
{
"Sat-Sun"
}
else
{
"Mon-Tue-Wed-Thu-Fri"
}
}
Sys.setlocale("LC_TIME", "English")
data$wdORwe <- sapply(data$date, FUN=GetwdORwe)
library(lattice)
steps.interval.wdORwe <- aggregate(steps ~ interval + wdORwe, data, mean)
xyplot(steps ~ interval | wdORwe, data=steps.interval.wdORwe, layout=c(2,1), type='l')
# Clean upworkspace
rm(list=ls())
etwd("C:/Users/Massimo/Documents/Coursera/Data Science Specialization/5 - Reproducible Research/CourseProject1")
if (!file.exists("activity.csv")) {
unzip("activity.zip")
}
rawdata <- read.csv("activity.csv", colClass=c('integer', 'Date', 'integer'))
steps <- aggregate(steps ~ date, data=rawdata, FUN=sum, na.rm=TRUE)
names(steps)<-c("date","count")
library(ggplot2)
barplot(steps$count, names.arg=steps$date, main="Total number of steps taken each day",
xlab="date", ylab="steps count")
steps <- aggregate(steps ~ date, data=rawdata, FUN=sum, na.rm=TRUE)
names(steps)<-c("date","count")
library(ggplot2)
barplot(steps$count, names.arg=steps$date, main="Total number of steps taken each day",
xlab="date", ylab="steps count")
# Clean upworkspace
rm(list=ls())
# 1. Code for reading in the dataset and/or processing the data
setwd("C:/Users/Massimo/Documents/Coursera/Data Science Specialization/5 - Reproducible Research/CourseProject1/RepData_PeerAssessment1")
if (!file.exists("activity.csv")) {
unzip("activity.zip")
}
rawdata <- read.csv("activity.csv", colClass=c('integer', 'Date', 'integer'))
# 2. Histogram of the total number of steps taken each day
steps <- aggregate(steps ~ date, data=rawdata, FUN=sum, na.rm=TRUE)
names(steps)<-c("date","count")
library(ggplot2)
barplot(steps$count, names.arg=steps$date, main="Total number of steps taken each day",
xlab="date", ylab="steps count")
# 3. Mean and median number of steps taken each day
mean.step.eachday <-  mean(steps$count, na.rm=TRUE)
median.stem.eachday <- median(steps$count, na.rm=TRUE)
avgs.maxnumsteps <- avgs[which.max(avgs$steps),]
# Clean upworkspace
rm(list=ls())
# 1. Code for reading in the dataset and/or processing the data
setwd("C:/Users/Massimo/Documents/Coursera/Data Science Specialization/5 - Reproducible Research/CourseProject1/RepData_PeerAssessment1")
if (!file.exists("activity.csv")) {
unzip("activity.zip")
}
rawdata <- read.csv("activity.csv", colClass=c('integer', 'Date', 'integer'))
# 2. Histogram of the total number of steps taken each day
steps <- aggregate(steps ~ date, data=rawdata, FUN=sum, na.rm=TRUE)
names(steps)<-c("date","count")
library(ggplot2)
barplot(steps$count, names.arg=steps$date, main="Total number of steps taken each day",
xlab="date", ylab="steps count")
# 3. Mean and median number of steps taken each day
mean.step.eachday <-  mean(steps$count, na.rm=TRUE)
median.stem.eachday <- median(steps$count, na.rm=TRUE)
# 4. Time series plot of the average number of steps taken
avgs <- aggregate(x=list(steps=rawdata$steps), by=list(interval=rawdata$interval),
FUN=mean, na.rm=TRUE)
plot(avgs, type='l', main="Average number of steps taken")
# 5. The 5-minute interval that, on average, contains the maximum number of steps
avgs.maxnumsteps <- avgs[which.max(avgs$steps),]
View(avgs.maxnumsteps)
avgs.maxnumsteps[1]
avgs.maxnumsteps[2]
# 6. Code to describe and show a strategy for imputing missing data
# Replace each missing value in an interval with the mean value of the day the interval belong to
data <- merge(rawdata, steps, by="date")
data["noNAsteps"] <- data$steps
nas <- is.na(data$steps)
data$noNAsteps[nas] <- data$count[nas]
sum(nas)
count(is.na(rawdata$steps))
sum(is.na(rawdata$steps))
